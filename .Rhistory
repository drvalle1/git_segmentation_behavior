traceplot(data = dat.res$nbrks, type = "nbrks", identity = identity)
View(behav.list)
traceplot(data = dat.res$LML, type = "LML", identity = identity)
ngibbs = 10000
## Run Gibbs sampler
plan(multisession)  #run all MCMC chains in parallel
dat.res<- behavior_segment(dat = behav.list, ngibbs = ngibbs)
801.833/60
## Traceplots
#type is either 'nbrks' or 'LML' for y-axis label
identity<- names(behav.list)
traceplot(data = dat.res$nbrks, type = "nbrks", identity = identity)
traceplot(data = dat.res$LML, type = "LML", identity = identity)
##Determine maximum likelihood (ML) for selecting breakpoints
ML<- apply(dat.res$LML, 1, function(x) getML(dat = x, nburn = 500))
ML
brkpts<- getBreakpts(dat = dat.res$brkpts, ML = ML, brk.cols = 99)  #brk.cols is max matrix cols
View(brkpts)
## Heatmaps
plot.heatmap(data = behav.list, brkpts = brkpts, dat.res = dat.res, type = "behav")
View(behav.list)
View(behav.list)
data<- behav.list[["7"]]
behav.heat<- behav.seg.image(data)
View(behav.heat)
behav.heat
View(behav.list)
View(behav.list[["1"]])
View(behav.list)
View(behav.list[["1"]])
#---------------------------------------------
behav.seg.image=function(dat, nbins) {  #Transform single var vectors into pres/abs matrices for heatmap; nbins is vector of bins per param in order
TA<- matrix(0, nrow(dat), nbins[1])
for (i in 1:nrow(dat)){
TA[i,dat$TA[i]]=1
}
SL<- matrix(0, nrow(dat), nbins[2])
for (i in 1:nrow(dat)){
SL[i,dat$SL[i]]=1
}
behav.list<- list(SL=SL,TA=TA)
behav.list
}
source('helper functions.R')
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
source('helper functions.R')
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
ngibbs = 20000
## Run Gibbs sampler
plan(multisession)  #run all MCMC chains in parallel
dat.res<- behavior_segment(dat = behav.list, ngibbs = ngibbs)
1738/60
traceplot(data = dat.res$LML, type = "LML", identity = identity)
##Determine maximum likelihood (ML) for selecting breakpoints
ML<- apply(dat.res$LML, 1, function(x) getML(dat = x, nburn = 500))
brkpts<- getBreakpts(dat = dat.res$brkpts, ML = ML, brk.cols = 99)  #brk.cols is max matrix cols
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
ngibbs = 40000
## Run Gibbs sampler
plan(multisession)  #run all MCMC chains in parallel
dat.res<- behavior_segment(dat = behav.list, ngibbs = ngibbs)
3546/60
## Traceplots
#type is either 'nbrks' or 'LML' for y-axis label
identity<- names(behav.list)
traceplot(data = dat.res$nbrks, type = "nbrks", identity = identity)
traceplot(data = dat.res$LML, type = "LML", identity = identity)
##Determine maximum likelihood (ML) for selecting breakpoints
ML<- apply(dat.res$LML, 1, function(x) getML(dat = x, nburn = 500))
ML
brkpts<- getBreakpts(dat = dat.res$brkpts, ML = ML, brk.cols = 99)  #brk.cols is max matrix cols
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
View(brkpts)
dat_out<- map(behav.list, assign.time.seg) %>% map_dfr(`[`)  #assign time seg and make as DF
setwd("~/Documents/Snail Kite Project/Data/R Scripts/git_LDA_behavior")
write.csv(dat_out, "Snail Kite Gridded Data_larger_behav.csv", row.names = F)
set.seed(2)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(viridis)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
# dat<- dat %>% filter(id != 9 & id != 10.2 & id != 13  & id != 17)
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
View(obs)
res=LDA_behavior_gibbs(dat=obs,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn)
dat<- obs
nobs=nrow(dat)
#separate variables
ind=grep('y1',colnames(dat))
y1=data.matrix(dat[,ind])
b1=length(ind)
ind=grep('y2',colnames(dat))
y2=data.matrix(dat[,ind])
b2=length(ind)
#initial values
phi1=matrix(1/b1,nmaxclust,b1)
phi2=matrix(1/b2,nmaxclust,b2)
theta=matrix(1/nmaxclust,nobs,nmaxclust)
z1.agg=array(NA,dim=c(nobs,b1,nmaxclust))
z2.agg=array(NA,dim=c(nobs,b2,nmaxclust))
for (i in 1:nobs){
for (j in 1:b1){
z1.agg[i,j,]=rmultinom(1,size=y1[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
for (j in 1:b2){
z2.agg[i,j,]=rmultinom(1,size=y2[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
}
for (i in 1:nobs){
print(i)
for (j in 1:b1){
# print(j)
z1.agg[i,j,]=rmultinom(1,size=y1[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
for (j in 1:b2){
z2.agg[i,j,]=rmultinom(1,size=y2[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
}
obs[is.na(obs),]
apply(obs, 1, max) %>% which(is.na(.))
apply(obs, 1, max) %>% which(.==NA)
apply(obs, 1, max)
foo<-
apply(obs, 1, max)
which(foo==NA)
which(is.na(foo))
z1.agg=array(0,dim=c(nobs,b1,nmaxclust))
z2.agg=array(0,dim=c(nobs,b2,nmaxclust))
for (i in 1:nobs){
print(i)
for (j in 1:b1){
# print(j)
z1.agg[i,j,]=rmultinom(1,size=y1[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
for (j in 1:b2){
z2.agg[i,j,]=rmultinom(1,size=y2[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
}
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
# dat<- dat %>% filter(id != 9 & id != 10.2 & id != 13  & id != 17)
dat$date<- dat$date %>% as_datetime()
#create list of input and to store output
dat.list<- df.to.list(dat = dat)
id<- unique(dat$id)
n<- length(id)
obs.list<- vector("list", n)
names(obs.list)<- id
length(dat.list)
#calculate # of obs in each bin (per move param) by tseg
for (i in 1:length(dat.list)) {
dat.ind=dat.list[[i]]
ntseg=max(dat.ind$tseg)
#TA
TA<- matrix(0, ntseg, max(dat.list[[i]]$TA, na.rm = T))
colnames(TA)<- paste0("y1.",1:max(dat.list[[i]]$TA, na.rm = T))
for (j in 1:ntseg){
tmp<- dat.list[[i]] %>% filter(tseg == j) %>% dplyr::select(TA) %>% table()
TA[j,as.numeric(names(tmp))]<- tmp
}
#SL
SL<- matrix(0, ntseg, max(dat.ind$SL, na.rm = T))
colnames(SL)<- paste0("y2.",1:max(dat.ind$SL, na.rm = T))
for (j in 1:ntseg){
tmp<- dat.ind %>% filter(tseg == j) %>% dplyr::select(SL) %>% table()
SL[j,as.numeric(names(tmp))]<- tmp
}
id<- rep(unique(dat.ind$id), ntseg)
tseg<- 1:ntseg
behav.res<- cbind(id, tseg, TA, SL) %>% data.frame()
obs.list[[i]]<- behav.res
}
View(obs.list)
View(obs.list[["1"]])
View(obs.list[["7"]])
#obs<- do.call(rbind.data.frame, obs.list)
obs<- map_dfr(obs.list, `[`)
View(obs)
obs[is.na(obs)]
#------------------------------------------------
get.summary.stats_behav=function(dat){  #dat must have time.seg assigned; for all IDs
#create list of input and to store output
dat.list<- df.to.list(dat = dat)
id<- unique(dat$id)
n<- length(id)
obs.list<- vector("list", n)
names(obs.list)<- id
#calculate # of obs in each bin (per move param) by tseg
for (i in 1:length(dat.list)) {
dat.ind=dat.list[[i]]
ntseg=max(dat.ind$tseg)
#TA
TA<- matrix(0, ntseg, max(dat.list[[i]]$TA, na.rm = T))
colnames(TA)<- paste0("y1.",1:max(dat.list[[i]]$TA, na.rm = T))
for (j in 1:ntseg){
tmp<- dat.list[[i]] %>% filter(tseg == j) %>% dplyr::select(TA) %>% table()
TA[j,as.numeric(names(tmp))]<- tmp
}
#SL
SL<- matrix(0, ntseg, max(dat.ind$SL, na.rm = T))
colnames(SL)<- paste0("y2.",1:max(dat.ind$SL, na.rm = T))
for (j in 1:ntseg){
tmp<- dat.ind %>% filter(tseg == j) %>% dplyr::select(SL) %>% table()
SL[j,as.numeric(names(tmp))]<- tmp
}
id<- rep(unique(dat.ind$id), ntseg)
tseg<- 1:ntseg
behav.res<- cbind(id, tseg, TA, SL) %>% data.frame()
obs.list[[i]]<- behav.res
}
#obs<- do.call(rbind.data.frame, obs.list)
obs<- map_dfr(obs.list, `[`)
obs[is.na(obs)]<- 0  #replace NAs w/ zero
obs
}
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
z1.agg=array(NA,dim=c(nobs,b1,nmaxclust))
z2.agg=array(NA,dim=c(nobs,b2,nmaxclust))
for (i in 1:nobs){
for (j in 1:b1){
z1.agg[i,j,]=rmultinom(1,size=y1[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
for (j in 1:b2){
z2.agg[i,j,]=rmultinom(1,size=y2[i,j],prob=rep(1/nmaxclust,nmaxclust))
}
}
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
# dat<- dat %>% filter(id != 9 & id != 10.2 & id != 13  & id != 17)
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
res=LDA_behavior_gibbs(dat=obs,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn)
#Check traceplot of log marginal likelihood
plot(res$loglikel,type='l')
#Extract and plots proportions of behaviors per time segment
theta.post<- res$theta[(nburn+1):ngibbs,]
theta.estim<- theta.post %>% apply(2, mean) %>% matrix(nrow(obs), nmaxclust) #calc mean of posterior
# png("Boxplot of behavior probs.png", width = 7, height = 5, units = "in", res = 300)
boxplot(theta.estim, xlab="Behavior", ylab="Probability of Behavior Occurrence")
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
behav.res<- get_behav_hist(res)
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of proportion data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "fixed")
#Assign behaviors (via theta) to each time segment
theta.estim<- apply(theta.estim[,1:3], 1, function(x) x/sum(x)) %>% t()  #normalize probs for only first 3 behaviors being used
theta.estim<- data.frame(id = obs$id, tseg = obs$tseg, theta.estim)
names(theta.estim)<- c("id", "tseg", "ARS","Transit","Resting")  #define behaviors
nobs<- data.frame(id = obs$id, tseg = obs$tseg, n = apply(obs[,11:16], 1, sum)) #calc obs per tseg using SL bins (more reliable than TA)
#Create augmented matrix by replicating rows (tsegs) according to obs per tseg
theta.estim2<- aug_behav_df(dat = dat, theta.estim = theta.estim, nobs = nobs)
View(nobs)
summary(nobs$n)
which(nobs$n == 0)
View(brkpts)
setwd("~/Documents/Snail Kite Project/Data/R Scripts/git_segmentation_behavior")
max.time=11000
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=1)
sample(max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
sample(2:max.time,size=10)
library(tidyverse)
library(tictoc)
library(furrr)
library(viridis)
library(lubridate)
source('gibbs functions2.R')
source('helper functions.R')
source('gibbs sampler2.R')
dat<- read.csv("Snail Kite Gridded Data_larger.csv", header = T, sep = ",")
dat$date<- dat$date %>% as_datetime()
#if dt within 5 min of 1 hr, round to 1 hr
dat<- round_track_time(dat = dat, int = 3600, tol = 5/60*3600)
dat.list<- df.to.list(dat=dat)
behav.list<- behav.prep(dat=dat, tstep = 3600)  #add move params and filter by 3600 s interval
behav.list<- behav.list[sapply(behav.list, nrow) > 2]  #remove IDs w/ fewer than 3 obs
ngibbs = 40000
## Run Gibbs sampler
plan(multisession)  #run all MCMC chains in parallel
dat.res<- behavior_segment(dat = behav.list, ngibbs = ngibbs)
3511/60
## Traceplots
#type is either 'nbrks' or 'LML' for y-axis label
identity<- names(behav.list)
traceplot(data = dat.res$LML, type = "LML", identity = identity)
##Determine maximum likelihood (ML) for selecting breakpoints
ML<- apply(dat.res$LML, 1, function(x) getML(dat = x, nburn = 500))
ML
brkpts<- getBreakpts(dat = dat.res$brkpts, ML = ML, brk.cols = 99)  #brk.cols is max matrix cols
View(brkpts)
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
## Heatmaps
plot.heatmap(data = behav.list, nbins = c(6,8), brkpts = brkpts, dat.res = dat.res, type = "behav")
dat_out<- map(behav.list, assign.time.seg) %>% map_dfr(`[`)  #assign time seg and make as DF
setwd("~/Documents/Snail Kite Project/Data/R Scripts/git_LDA_behavior")
write.csv(dat_out, "Snail Kite Gridded Data_larger_behav.csv", row.names = F)
set.seed(2)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(viridis)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
View(obs)
obs[is.na(obs)]
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
res=LDA_behavior_gibbs(dat=obs,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn)
#Check traceplot of log marginal likelihood
plot(res$loglikel,type='l')
#Extract and plots proportions of behaviors per time segment
theta.post<- res$theta[(nburn+1):ngibbs,]
theta.estim<- theta.post %>% apply(2, mean) %>% matrix(nrow(obs), nmaxclust) #calc mean of posterior
# png("Boxplot of behavior probs.png", width = 7, height = 5, units = "in", res = 300)
boxplot(theta.estim, xlab="Behavior", ylab="Probability of Behavior Occurrence")
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
behav.res<- get_behav_hist(res)
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of proportion data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "fixed")
#Assign behaviors (via theta) to each time segment
theta.estim<- apply(theta.estim[,1:3], 1, function(x) x/sum(x)) %>% t()  #normalize probs for only first 3 behaviors being used
theta.estim<- data.frame(id = obs$id, tseg = obs$tseg, theta.estim)
names(theta.estim)<- c("id", "tseg", "ARS","Transit","Resting")  #define behaviors
nobs<- data.frame(id = obs$id, tseg = obs$tseg, n = apply(obs[,11:16], 1, sum)) #calc obs per tseg using SL bins (more reliable than TA)
View(nobs)
summary(nobs$n)
#Create augmented matrix by replicating rows (tsegs) according to obs per tseg
theta.estim2<- aug_behav_df(dat = dat, theta.estim = theta.estim, nobs = nobs)
#Change into long format
theta.estim.long<- theta.estim2 %>% gather(key, value, -id, -tseg, -time1, -date)
theta.estim.long$date<- theta.estim.long$date %>% as_datetime()
names(theta.estim.long)[5:6]<- c("behavior","prop")
theta.estim.long$behavior<- factor(theta.estim.long$behavior, levels = c("Resting","ARS","Transit"))
#stacked area
ggplot(theta.estim.long) +
geom_area(aes(x=time1, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
labs(x = "\nObservation", y = "Proportion of Behavior\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
facet_wrap(~id, scales = "free_x")
View(theta.estim.long)
#stacked area
ggplot(theta.estim.long %>% filter(id==1)) +
geom_area(aes(x=time1, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
labs(x = "\nObservation", y = "Proportion of Behavior\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
facet_wrap(~id, scales = "free_x")
dat2<- assign_behav(dat.list = dat.list, theta.estim2 = theta.estim2)
dat2$behav<- factor(dat2$behav, levels = c("Resting","ARS","Transit"))
#load map data
usa <- ne_states(country = "United States of America", returnclass = "sf")
fl<- usa %>% filter(name == "Florida")
fl<- st_transform(fl, crs = "+init=epsg:32617") #change projection to UTM 17N
# Facet plot of maps
ggplot() +
geom_sf(data = fl) +
coord_sf(xlim = c(min(dat$x-120000), max(dat$x+40000)),
ylim = c(min(dat$y-20000), max(dat$y+20000)), expand = FALSE) +
geom_path(data = dat2, aes(x=x, y=y), color="gray60", size=0.25) +
geom_point(data = dat2, aes(x, y, fill=behav), size=2.5, pch=21, alpha=dat2$prop) +
scale_fill_viridis_d("Behavior", direction = -1) +
labs(x = "Longitude", y = "Latitude") +
theme_bw() +
theme(axis.title = element_text(size = 16),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
guides(fill = guide_legend(label.theme = element_text(size = 12),
title.theme = element_text(size = 14))) +
facet_wrap(~id)
# Facet plot of maps
ggplot() +
geom_sf(data = fl) +
coord_sf(xlim = c(min(dat$x-120000), max(dat$x+40000)),
ylim = c(min(dat$y-20000), max(dat$y+20000)), expand = FALSE) +
geom_path(data = dat2, aes(x=x, y=y), color="gray60", size=0.25) +
geom_point(data = dat2, aes(x, y, fill=behav), size=2.5, pch=21, alpha=dat2$prop) +
scale_fill_viridis_d("Behavior", direction = -1) +
labs(x = "Longitude", y = "Latitude") +
theme_bw() +
theme(axis.title = element_text(size = 16),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
guides(fill = guide_legend(label.theme = element_text(size = 12),
title.theme = element_text(size = 14))) +
facet_wrap(~id)
