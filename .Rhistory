cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
res.estim=matrix(NA,length(seq1),nrow(res2))
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
res.estim[,k]=prob
}
plot(NA,NA,xlim=c(-1,1),ylim=c(0,max(res.estim)))
for (k in 1:nrow(res2)){
lines(seq1,res.estim[,k],col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
seq1=seq(from=-1,to=1,length.out=1000)
for (i in 1:length(b0)){
for (j in 1:length(nobs)){
cond=res1$converge==1 & res1$b0.true==b0[i] & res1$nobs==nobs[j]
res2=res1[cond,]
#get estimated curves
res.estim=matrix(NA,length(seq1),nrow(res2))
for (k in 1:nrow(res2)){
b0.estim=res2$b0[k]
b1.estim=res2$b1[k]
tmp=b0.estim+b1.estim*seq1
prob=exp(tmp)/(1+exp(tmp))
res.estim[,k]=prob
}
plot(NA,NA,xlim=c(-1,1),ylim=c(0,max(res.estim)),main=c(b0[i],nobs[j]))
for (k in 1:nrow(res2)){
lines(seq1,res.estim[,k],col='grey')
}
#true curve
tmp=b0[i]+b1*seq1
prob=exp(tmp)/(1+exp(tmp))
lines(seq1,prob,col='red')
}
}
rm(list=ls(all=TRUE))
set.seed(1)
#Is the estimated variance of beta smaller for case-control than for random sampling?
nsim=100
nobs=10000
b0=-c(6:1)
b1=-2
oo=1
conv.cc=conv.rs=warn.rs=rep(NA,nsim*length(b0))
res.cc=res.rs=matrix(NA,nsim*length(b0),8)
for (i in 1:nsim){
# print(i)
for (k in 1:length(b0)){
b0a=b0[k]
x=runif(nobs,min=-1,max=1)
tmp=b0a+b1*x
prob=exp(tmp)/(1+exp(tmp)); mean(prob)
y=rbinom(nobs,size=1,prob=prob)
#case-control
ind1=which(y==1)
ind0=sample(which(y==0),size=length(ind1))
ind=c(ind0,ind1)
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.cc[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.cc[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
prec=t(xmat)%*%w%*%xmat
print(diag(1/prec),diag(cov.est))
#random sampling
ind=sample(1:nobs,size=length(ind))
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.rs[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.rs[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
oo=oo+1
}
}
prec
diag(1/prec)
diag(1/prec)
diag(cov.est)
rm(list=ls(all=TRUE))
set.seed(1)
#Is the estimated variance of beta smaller for case-control than for random sampling?
nsim=100
nobs=10000
b0=-c(6:1)
b1=-2
oo=1
conv.cc=conv.rs=warn.rs=rep(NA,nsim*length(b0))
res.cc=res.rs=matrix(NA,nsim*length(b0),8)
for (i in 1:nsim){
# print(i)
for (k in 1:length(b0)){
b0a=b0[k]
x=runif(nobs,min=-1,max=1)
tmp=b0a+b1*x
prob=exp(tmp)/(1+exp(tmp)); mean(prob)
y=rbinom(nobs,size=1,prob=prob)
#case-control
ind1=which(y==1)
ind0=sample(which(y==0),size=length(ind1))
ind=c(ind0,ind1)
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.cc[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
prec=t(xmat)%*%w%*%xmat
cov.est=solve(prec)
res.cc[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
print(c(diag(1/prec),diag(cov.est)))
#random sampling
ind=sample(1:nobs,size=length(ind))
dat=data.frame(y=y[ind],x=x[ind])
mod=glm(y~x,data=dat,family='binomial')
cov.true=vcov(mod)
conv.rs[oo]=mod$converged
#compare to my equations
xmat=data.matrix(cbind(1,dat$x))
pred=predict(mod,type='response')
w=diag(pred*(1-pred))
cov.est=solve(t(xmat)%*%w%*%xmat)
res.rs[oo,]=c(as.numeric(cov.true),as.numeric(cov.est))
oo=oo+1
}
}
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-2)
which(diff1==min(diff1))
diff1
tail(diff1)
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-0.95)
which(diff1==min(diff1))
seq1=seq(from=0.01,to=100,length.out=10000)
fim=data.frame(param=seq1,p95=pgamma(2,seq1,seq1))
diff1=abs(fim$p95-0.95)
which(diff1==min(diff1))
fim[356,]
param=fim$param[356]
seq1=seq(from=0.01,to=10,length.out=10000)
plot(seq1,dgamma(seq1,param,param),type='l')
param
z=rgamma(100000,param,param)
mean(z<2)
mean(z)
mean(z<0.1)
rm(list=ls(all=TRUE))
setwd('U:\\uf\\courses\\stats\\2019 new exercises')
dat=read.csv('water gauge data.csv',as.is=T)
head(dat)
devtools::install_github('yihui/tinytex')
devtools::install_github("rmarkdown")
install.packages('rmarkdown')
install.packages("rmarkdown")
library('mgcv')
?predict.gam
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
bern.a=bern.b=1
#useful stuff
max.time=max(dat$time1)
max.SL=max(dat$SL)
max.TA=max(dat$TA)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,
alpha=alpha,bern.a=bern.a,bern.b=bern.b,
max.SL=max.SL,max.TA=max.TA)
}
length(breakpt)
abline(v=breakpt,lty=3,col='green')
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=100
#step length (multinomial with 4 categories)
prob.SL=matrix(c(0.6,0.2,0.2,0.0,
0.2,0.1,0.5,0.2,
0.0,0.1,0.2,0.7),3,4,byrow=T)
#apply(prob.SL,1,sum) #basic checking
ind=sample(3,size=nseg,replace=T)
prob.SL1=prob.SL[ind,]
#turning angle  (multinomial with 4 categories)
prob.TA=matrix(c(0.6,0.2,0.1,0.1,
0.3,0.3,0.2,0.2,
0.2,0.1,0.5,0.2,
0.1,0.1,0.1,0.7),4,4,byrow=T)
#apply(prob.TA,1,sum)  #basic checking
ind=sample(4,size=nseg,replace=T)
prob.TA1=prob.TA[ind,]
#turning angle autocorrelation (bernoulli)
prob.TAA=c(0.5,0.9)
ind=sample(2,size=nseg,replace=T)
prob.TAA1=prob.TAA[ind]
#generate observations
obs=matrix(NA,nobs,3)
for (i in 1:nobs){
tmp.SL=rmultinom(1,size=1,prob=prob.SL1[seg.index[i],])
tmp.TA=rmultinom(1,size=1,prob=prob.TA1[seg.index[i],])
tmp.TAA=rbinom(1,size=1,prob=prob.TAA1[seg.index[i]])
obs[i,]=c(which(tmp.SL==1),which(tmp.TA==1),tmp.TAA)
}
#plot these data
par(mfrow=c(3,1))
for (i in 1:3){
plot(obs[,i])
abline(v=cumsum(partition))
}
obs1=data.frame(SL=obs[,1],TA=obs[,2],TAA=obs[,3])
obs1$time1=1:nobs
ind
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(1)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=100
#step length (multinomial with 4 categories)
prob.SL=matrix(c(0.6,0.2,0.2,0.0,
0.2,0.1,0.5,0.2,
0.0,0.1,0.2,0.7),3,4,byrow=T)
#apply(prob.SL,1,sum) #basic checking
ind=sample(3,size=nseg,replace=T)
prob.SL1=prob.SL[ind,]
#turning angle  (multinomial with 4 categories)
prob.TA=matrix(c(0.6,0.3,0.1,0.0,
0.3,0.3,0.2,0.2,
0.0,0.1,0.7,0.2,
0.0,0.1,0.2,0.7),4,4,byrow=T)
#apply(prob.TA,1,sum)  #basic checking
ind=sample(4,size=nseg,replace=T)
prob.TA1=prob.TA[ind,]
#turning angle autocorrelation (bernoulli)
prob.TAA=c(0.5,0.9)
ind=sample(2,size=nseg,replace=T)
prob.TAA1=prob.TAA[ind]
#generate observations
obs=matrix(NA,nobs,3)
for (i in 1:nobs){
tmp.SL=rmultinom(1,size=1,prob=prob.SL1[seg.index[i],])
tmp.TA=rmultinom(1,size=1,prob=prob.TA1[seg.index[i],])
tmp.TAA=rbinom(1,size=1,prob=prob.TAA1[seg.index[i]])
obs[i,]=c(which(tmp.SL==1),which(tmp.TA==1),tmp.TAA)
}
#plot these data
par(mfrow=c(3,1))
for (i in 1:3){
plot(obs[,i])
abline(v=cumsum(partition))
}
obs1=data.frame(SL=obs[,1],TA=obs[,2],TAA=obs[,3])
obs1$time1=1:nobs
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(2)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=100
#step length (multinomial with 4 categories)
prob.SL=matrix(c(0.6,0.2,0.2,0.0,
0.2,0.1,0.5,0.2,
0.0,0.1,0.2,0.7),3,4,byrow=T)
#apply(prob.SL,1,sum) #basic checking
ind=sample(3,size=nseg,replace=T)
prob.SL1=prob.SL[ind,]
#turning angle  (multinomial with 4 categories)
prob.TA=matrix(c(0.6,0.3,0.1,0.0,
0.3,0.3,0.2,0.2,
0.0,0.1,0.7,0.2,
0.0,0.1,0.2,0.7),4,4,byrow=T)
#apply(prob.TA,1,sum)  #basic checking
ind=sample(4,size=nseg,replace=T)
prob.TA1=prob.TA[ind,]
#turning angle autocorrelation (bernoulli)
prob.TAA=c(0.3,0.9)
ind=sample(2,size=nseg,replace=T)
prob.TAA1=prob.TAA[ind]
#generate observations
obs=matrix(NA,nobs,3)
for (i in 1:nobs){
tmp.SL=rmultinom(1,size=1,prob=prob.SL1[seg.index[i],])
tmp.TA=rmultinom(1,size=1,prob=prob.TA1[seg.index[i],])
tmp.TAA=rbinom(1,size=1,prob=prob.TAA1[seg.index[i]])
obs[i,]=c(which(tmp.SL==1),which(tmp.TA==1),tmp.TAA)
}
#plot these data
par(mfrow=c(3,1))
for (i in 1:3){
plot(obs[,i])
abline(v=cumsum(partition))
}
obs1=data.frame(SL=obs[,1],TA=obs[,2],TAA=obs[,3])
obs1$time1=1:nobs
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(2)
nobs=1000
nseg=10
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=100
#step length (multinomial with 4 categories)
prob.SL=matrix(c(0.6,0.2,0.2,0.0,
0.2,0.1,0.5,0.2,
0.0,0.1,0.2,0.7),3,4,byrow=T)
#apply(prob.SL,1,sum) #basic checking
ind=sample(3,size=nseg,replace=T)
prob.SL1=prob.SL[ind,]
#turning angle  (multinomial with 4 categories)
prob.TA=matrix(c(0.6,0.3,0.1,0.0,
0.3,0.3,0.2,0.2,
0.0,0.1,0.7,0.2,
0.0,0.1,0.2,0.7),4,4,byrow=T)
#apply(prob.TA,1,sum)  #basic checking
ind=sample(4,size=nseg,replace=T)
prob.TA1=prob.TA[ind,]
#turning angle autocorrelation (bernoulli)
prob.TAA=c(0.3,0.9)
ind=sample(2,size=nseg,replace=T)
prob.TAA1=prob.TAA[ind]
#generate observations
obs=matrix(NA,nobs,3)
for (i in 1:nobs){
tmp.SL=rmultinom(1,size=1,prob=prob.SL1[seg.index[i],])
tmp.TA=rmultinom(1,size=1,prob=prob.TA1[seg.index[i],])
tmp.TAA=rbinom(1,size=1,prob=prob.TAA1[seg.index[i]])
obs[i,]=c(which(tmp.SL==1),which(tmp.TA==1),tmp.TAA)
}
#plot these data
par(mfrow=c(3,1))
for (i in 1:3){
plot(obs[,i])
abline(v=cumsum(partition))
}
obs1=data.frame(SL=obs[,1],TA=obs[,2],TAA=obs[,3])
obs1$time1=1:nobs
setwd('U:\\GIT_models\\git_segmentation_behavior')
write.csv(obs1,'fake data.csv',row.names=F)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
dat=read.csv('fake data.csv',as.is=T)
#priors
alpha=0.01
bern.a=bern.b=1
#useful stuff
max.time=max(dat$time1)
max.SL=max(dat$SL)
max.TA=max(dat$TA)
#starting values
breakpt=mean(dat$time1)
ngibbs=10000
for (i in 1:ngibbs){
print(i)
breakpt=samp.move(breakpt=breakpt,max.time=max.time,dat=dat,
alpha=alpha,bern.a=bern.a,bern.b=bern.b,
max.SL=max.SL,max.TA=max.TA)
}
length(breakpt)
abline(v=breakpt,lty=3,col='green')
setwd('U:\\GIT_models\\git_segmentation_behavior')
dat=read.csv('fake data.csv',as.is=T)
head(dat)
tail(dat)
rm(list=ls(all=TRUE))
library('MCMCpack')
set.seed(4)
nobs=2000
nseg=20
tmp=runif(nseg)
prob=tmp/sum(tmp); prob
partition=rmultinom(1,size=nobs,prob=prob)
seg.index=rep(1:nseg,times=partition)
nloc=100
#generate probabilities for each type of data
ncat.data=c(8,3,10,2,4,6) #number of bins for each data type
ndata.type=length(ncat.data)
probs=list()
for (i in 1:ndata.type){
probs[[i]]=rdirichlet(nseg,alpha=rep(0.1,ncat.data[i]))
}
#generate observations
obs=matrix(NA,nobs,ndata.type)
for (i in 1:nobs){
for (j in 1:ndata.type){
tmp=rmultinom(1,size=1,prob=probs[[j]][seg.index[i],])
obs[i,j]=which(tmp==1)
}
}
#name these variables
nome=paste0('y',1:ndata.type)
colnames(obs)=nome
#plot these data
par(mfrow=c(ndata.type,1),mar=rep(1,4))
for (i in 1:ndata.type){
plot(obs[,i])
abline(v=cumsum(partition))
}
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
source('gibbs sampler main function.R')
dat=read.csv('fake data.csv',as.is=T)
ndata.types=ncol(dat)
#priors
alpha=0.01
ngibbs=5000
#run gibbs sampler
breakpt=time.segm.behavior(dat=dat,ngibbs=ngibbs)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
source('gibbs sampler main function.R')
dat=read.csv('fake data.csv',as.is=T)
ndata.types=ncol(dat)
#priors
alpha=0.01
ngibbs=5000
#run gibbs sampler
breakpt=time.segm.behavior(dat=dat,ngibbs=ngibbs)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
source('gibbs sampler main function.R')
dat=read.csv('fake data.csv',as.is=T)
ndata.types=ncol(dat)
#priors
alpha=0.01
ngibbs=5000
#run gibbs sampler
breakpt=time.segm.behavior(dat=dat,ngibbs=ngibbs)
breakpt
dim(dat)
rm(list=ls(all=TRUE))
set.seed(1)
setwd('U:\\GIT_models\\git_segmentation_behavior')
source('gibbs functions.R')
source('gibbs sampler main function.R')
dat=read.csv('fake data.csv',as.is=T)
ndata.types=ncol(dat)
#priors
alpha=0.01
ngibbs=5000
#run gibbs sampler
breakpt=time.segm.behavior(dat=dat,ngibbs=ngibbs,breakpt=c(3,5))
breakpt
